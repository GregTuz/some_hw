{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8830fe52-3192-4064-a0d7-73622ecb1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructType, IntegerType, DateType, StructField\n",
    "from pyspark.sql.functions import split, expr, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d5147c-f4e2-4220-a40b-6c33c6d5cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:45:17 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "24/11/24 23:45:17 INFO SparkUI: Stopped Spark web UI at http://192.168.1.68:4040\n",
      "24/11/24 23:45:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "24/11/24 23:45:17 INFO MemoryStore: MemoryStore cleared\n",
      "24/11/24 23:45:17 INFO BlockManager: BlockManager stopped\n",
      "24/11/24 23:45:17 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "24/11/24 23:45:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "24/11/24 23:45:17 INFO SparkContext: Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107b1dfd-a73a-4bff-b568-4df16e552cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:49:22 WARN Utils: Your hostname, MacBook-Air-15.local resolves to a loopback address: 127.0.0.1; using 192.168.1.68 instead (on interface en0)\n",
      "24/11/24 23:49:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/tuzhbagrigoriy/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/tuzhbagrigoriy/.ivy2/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c25bc631-7024-45f9-8726-d75bfc9c8a32;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.4.1 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.tukaani#xz;1.9 in central\n",
      ":: resolution report :: resolve 89ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.spark#spark-avro_2.12;3.4.1 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c25bc631-7024-45f9-8726-d75bfc9c8a32\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/2ms)\n",
      "24/11/24 23:49:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/24 23:49:22 WARN DependencyUtils: Local jar /Users/tuzhbagrigoriy/reps/some_hw/python_dz/HW9/postgresql-42.7.4.jar does not exist, skipping.\n",
      "24/11/24 23:49:22 INFO SparkContext: Running Spark version 3.5.3\n",
      "24/11/24 23:49:22 INFO SparkContext: OS info Mac OS X, 14.6.1, aarch64\n",
      "24/11/24 23:49:22 INFO SparkContext: Java version 1.8.0_431\n",
      "24/11/24 23:49:22 INFO ResourceUtils: ==============================================================\n",
      "24/11/24 23:49:22 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/11/24 23:49:22 INFO ResourceUtils: ==============================================================\n",
      "24/11/24 23:49:22 INFO SparkContext: Submitted application: spark_demo_1\n",
      "24/11/24 23:49:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/11/24 23:49:22 INFO ResourceProfile: Limiting resource is cpu\n",
      "24/11/24 23:49:22 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/11/24 23:49:22 INFO SecurityManager: Changing view acls to: tuzhbagrigoriy\n",
      "24/11/24 23:49:22 INFO SecurityManager: Changing modify acls to: tuzhbagrigoriy\n",
      "24/11/24 23:49:22 INFO SecurityManager: Changing view acls groups to: \n",
      "24/11/24 23:49:22 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/11/24 23:49:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: tuzhbagrigoriy; groups with view permissions: EMPTY; users with modify permissions: tuzhbagrigoriy; groups with modify permissions: EMPTY\n",
      "24/11/24 23:49:22 INFO Utils: Successfully started service 'sparkDriver' on port 55372.\n",
      "24/11/24 23:49:22 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/11/24 23:49:22 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/11/24 23:49:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/11/24 23:49:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/11/24 23:49:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/11/24 23:49:22 INFO DiskBlockManager: Created local directory at /private/var/folders/q9/8d414xl96td8wy4mhjq3fkgm0000gn/T/blockmgr-8469aaf4-0f28-4dbd-b983-590c4acaa86c\n",
      "24/11/24 23:49:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB\n",
      "24/11/24 23:49:22 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/11/24 23:49:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/11/24 23:49:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/11/24 23:49:23 ERROR SparkContext: Failed to add postgresql-42.7.4.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /Users/tuzhbagrigoriy/reps/some_hw/python_dz/HW9/postgresql-42.7.4.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/11/24 23:49:23 INFO SparkContext: Added file file:///Users/tuzhbagrigoriy/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.4.1.jar at file:///Users/tuzhbagrigoriy/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.4.1.jar with timestamp 1732481362746\n",
      "24/11/24 23:49:23 INFO Utils: Copying /Users/tuzhbagrigoriy/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.4.1.jar to /private/var/folders/q9/8d414xl96td8wy4mhjq3fkgm0000gn/T/spark-50dbbc98-5b4b-42ac-bc20-68cc740ad280/userFiles-0574d265-56bf-48ca-93c8-0fd157ba07b3/org.apache.spark_spark-avro_2.12-3.4.1.jar\n",
      "24/11/24 23:49:23 INFO SparkContext: Added file file:///Users/tuzhbagrigoriy/.ivy2/jars/org.tukaani_xz-1.9.jar at file:///Users/tuzhbagrigoriy/.ivy2/jars/org.tukaani_xz-1.9.jar with timestamp 1732481362746\n",
      "24/11/24 23:49:23 INFO Utils: Copying /Users/tuzhbagrigoriy/.ivy2/jars/org.tukaani_xz-1.9.jar to /private/var/folders/q9/8d414xl96td8wy4mhjq3fkgm0000gn/T/spark-50dbbc98-5b4b-42ac-bc20-68cc740ad280/userFiles-0574d265-56bf-48ca-93c8-0fd157ba07b3/org.tukaani_xz-1.9.jar\n",
      "24/11/24 23:49:23 INFO Executor: Starting executor ID driver on host 192.168.1.68\n",
      "24/11/24 23:49:23 INFO Executor: OS info Mac OS X, 14.6.1, aarch64\n",
      "24/11/24 23:49:23 INFO Executor: Java version 1.8.0_431\n",
      "24/11/24 23:49:23 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "24/11/24 23:49:23 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@341c34c6 for default.\n",
      "24/11/24 23:49:23 INFO Executor: Fetching file:///Users/tuzhbagrigoriy/.ivy2/jars/org.tukaani_xz-1.9.jar with timestamp 1732481362746\n",
      "24/11/24 23:49:23 INFO Utils: /Users/tuzhbagrigoriy/.ivy2/jars/org.tukaani_xz-1.9.jar has been previously copied to /private/var/folders/q9/8d414xl96td8wy4mhjq3fkgm0000gn/T/spark-50dbbc98-5b4b-42ac-bc20-68cc740ad280/userFiles-0574d265-56bf-48ca-93c8-0fd157ba07b3/org.tukaani_xz-1.9.jar\n",
      "24/11/24 23:49:23 INFO Executor: Fetching file:///Users/tuzhbagrigoriy/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.4.1.jar with timestamp 1732481362746\n",
      "24/11/24 23:49:23 INFO Utils: /Users/tuzhbagrigoriy/.ivy2/jars/org.apache.spark_spark-avro_2.12-3.4.1.jar has been previously copied to /private/var/folders/q9/8d414xl96td8wy4mhjq3fkgm0000gn/T/spark-50dbbc98-5b4b-42ac-bc20-68cc740ad280/userFiles-0574d265-56bf-48ca-93c8-0fd157ba07b3/org.apache.spark_spark-avro_2.12-3.4.1.jar\n",
      "24/11/24 23:49:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55373.\n",
      "24/11/24 23:49:23 INFO NettyBlockTransferService: Server created on 192.168.1.68:55373\n",
      "24/11/24 23:49:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/11/24 23:49:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.68, 55373, None)\n",
      "24/11/24 23:49:23 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.68:55373 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.1.68, 55373, None)\n",
      "24/11/24 23:49:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.68, 55373, None)\n",
      "24/11/24 23:49:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.68, 55373, None)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"spark_demo_1\") \\\n",
    "            .config(\"spark.jars\", \"postgresql-42.7.4.jar\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.4.1\") \\\n",
    "            .master(\"local\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0e2b93-8238-44cd-a2fe-4a577684853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"file:///Users/tuzhbagrigoriy/Downloads/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fc50d8-0cc5-44a3-839f-7faa9967e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:49:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "24/11/24 23:49:23 INFO SharedState: Warehouse path is 'file:/Users/tuzhbagrigoriy/reps/some_hw/python_dz/HW9/spark-warehouse'.\n",
      "24/11/24 23:49:23 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.\n",
      "24/11/24 23:49:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 357.1 KiB, free 366.0 MiB)\n",
      "24/11/24 23:49:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.68:55373 (size: 35.2 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:49:24 INFO FileInputFormat: Total input files to process : 1\n",
      "24/11/24 23:49:24 INFO FileInputFormat: Total input files to process : 1\n",
      "24/11/24 23:49:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/11/24 23:49:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.6 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.68:55373 (size: 4.4 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/11/24 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.1.68, executor driver, partition 0, PROCESS_LOCAL, 9452 bytes) \n",
      "24/11/24 23:49:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/11/24 23:49:24 INFO BinaryFileRDD: Input split: Paths:/Users/tuzhbagrigoriy/Downloads/movies.csv:0+5073\n",
      "24/11/24 23:49:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1085 bytes result sent to driver\n",
      "24/11/24 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 217 ms on 192.168.1.68 (executor driver) (1/1)\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/11/24 23:49:24 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0,255 s\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0,280981 s\n",
      "24/11/24 23:49:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Missing parents: List()\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/11/24 23:49:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.68:55373 (size: 5.4 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "24/11/24 23:49:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.1.68, executor driver, partition 0, PROCESS_LOCAL, 9452 bytes) \n",
      "24/11/24 23:49:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "24/11/24 23:49:24 INFO BinaryFileRDD: Input split: Paths:/Users/tuzhbagrigoriy/Downloads/movies.csv:0+5073\n",
      "24/11/24 23:49:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1148 bytes result sent to driver\n",
      "24/11/24 23:49:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on 192.168.1.68 (executor driver) (1/1)\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "24/11/24 23:49:24 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,039 s\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/11/24 23:49:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "24/11/24 23:49:24 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,043047 s\n",
      "24/11/24 23:49:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.68:55373 in memory (size: 35.2 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.68:55373 in memory (size: 4.4 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.68:55373 in memory (size: 5.4 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "df = spark \\\n",
    "    .read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"quote\", \"*\") \\\n",
    "    .option(\"dateFormat\", \"M/d/y\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea8bd5e-2bae-4b64-85f7-cc821bf725e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:49:26 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/11/24 23:49:26 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/11/24 23:49:26 INFO CodeGenerator: Code generated in 84.824625 ms\n",
      "24/11/24 23:49:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 353.1 KiB, free 366.0 MiB)\n",
      "24/11/24 23:49:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.68:55373 (size: 35.1 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:26 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:49:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/11/24 23:49:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Missing parents: List()\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/11/24 23:49:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.3 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 365.9 MiB)\n",
      "24/11/24 23:49:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.68:55373 (size: 8.2 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/11/24 23:49:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "24/11/24 23:49:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.1.68, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes) \n",
      "24/11/24 23:49:26 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "24/11/24 23:49:26 INFO CodeGenerator: Code generated in 10.199792 ms\n",
      "24/11/24 23:49:26 INFO FileScanRDD: Reading File path: file:///Users/tuzhbagrigoriy/Downloads/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "24/11/24 23:49:26 INFO CodeGenerator: Code generated in 8.241625 ms\n",
      "24/11/24 23:49:26 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1773 bytes result sent to driver\n",
      "24/11/24 23:49:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on 192.168.1.68 (executor driver) (1/1)\n",
      "24/11/24 23:49:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "24/11/24 23:49:26 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0,087 s\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/11/24 23:49:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "24/11/24 23:49:26 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,089753 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------+---------------------+----------------+-------------+-----------------+---------------+----+\n",
      "|                      Film|  Genre|          Lead Studio|Audience score %|Profitability|Rotten Tomatoes %|Worldwide Gross|Year|\n",
      "+--------------------------+-------+---------------------+----------------+-------------+-----------------+---------------+----+\n",
      "|Zack and Miri Make a Porno|Romance|The Weinstein Company|              70|  1.747541667|               64|        $41.94 |2008|\n",
      "+--------------------------+-------+---------------------+----------------+-------------+-----------------+---------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:49:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.1.68:55373 in memory (size: 8.2 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:49:27 INFO CodeGenerator: Code generated in 14.266709 ms\n"
     ]
    }
   ],
   "source": [
    "df.show(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1810f0-85ea-493c-be63-01e2bedc5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('film_words', split(col('film'), ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "696f5aa4-cc80-4127-be31-60328392a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+---------+---------------------+----------------+-------------+-----------------+---------------+----+------------------------------------------+\n",
      "|                              Film|    Genre|          Lead Studio|Audience score %|Profitability|Rotten Tomatoes %|Worldwide Gross|Year|                                film_words|\n",
      "+----------------------------------+---------+---------------------+----------------+-------------+-----------------+---------------+----+------------------------------------------+\n",
      "|        Zack and Miri Make a Porno|  Romance|The Weinstein Company|              70|  1.747541667|               64|        $41.94 |2008|         [Zack, and, Miri, Make, a, Porno]|\n",
      "|                   Youth in Revolt|   Comedy|The Weinstein Company|              52|         1.09|               68|        $19.62 |2010|                       [Youth, in, Revolt]|\n",
      "|You Will Meet a Tall Dark Stranger|   Comedy|          Independent|              35|  1.211818182|               43|        $26.66 |2010|[You, Will, Meet, a, Tall, Dark, Stranger]|\n",
      "|                      When in Rome|   Comedy|               Disney|              44|          0.0|               15|        $43.04 |2010|                          [When, in, Rome]|\n",
      "|             What Happens in Vegas|   Comedy|                  Fox|              72|  6.267647029|               28|       $219.37 |2008|                [What, Happens, in, Vegas]|\n",
      "|               Water For Elephants|    Drama|     20th Century Fox|              72|  3.081421053|               60|       $117.09 |2011|                   [Water, For, Elephants]|\n",
      "|                            WALL-E|Animation|               Disney|              89|  2.896019067|               96|       $521.28 |2008|                                  [WALL-E]|\n",
      "|                          Waitress|  Romance|          Independent|              67|   11.0897415|               89|        $22.18 |2007|                                [Waitress]|\n",
      "|               Waiting For Forever|  Romance|          Independent|              53|        0.005|                6|         $0.03 |2011|                   [Waiting, For, Forever]|\n",
      "|                   Valentine's Day|   Comedy|         Warner Bros.|              54|  4.184038462|               17|       $217.57 |2010|                        [Valentine's, Day]|\n",
      "+----------------------------------+---------+---------------------+----------------+-------------+-----------------+---------------+----+------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:51:16 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/11/24 23:51:16 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/11/24 23:51:16 INFO CodeGenerator: Code generated in 14.332209 ms\n",
      "24/11/24 23:51:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 353.1 KiB, free 364.4 MiB)\n",
      "24/11/24 23:51:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 364.3 MiB)\n",
      "24/11/24 23:51:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.1.68:55373 (size: 35.1 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:16 INFO SparkContext: Created broadcast 11 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:51:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/11/24 23:51:16 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Got job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Missing parents: List()\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/11/24 23:51:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 19.8 KiB, free 364.3 MiB)\n",
      "24/11/24 23:51:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 364.3 MiB)\n",
      "24/11/24 23:51:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.1.68:55373 (size: 8.8 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/11/24 23:51:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "24/11/24 23:51:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (192.168.1.68, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes) \n",
      "24/11/24 23:51:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "24/11/24 23:51:16 INFO CodeGenerator: Code generated in 16.694291 ms\n",
      "24/11/24 23:51:16 INFO FileScanRDD: Reading File path: file:///Users/tuzhbagrigoriy/Downloads/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "24/11/24 23:51:16 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2962 bytes result sent to driver\n",
      "24/11/24 23:51:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 38 ms on 192.168.1.68 (executor driver) (1/1)\n",
      "24/11/24 23:51:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "24/11/24 23:51:16 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0,044 s\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/11/24 23:51:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "24/11/24 23:51:16 INFO DAGScheduler: Job 6 finished: showString at NativeMethodAccessorImpl.java:0, took 0,049604 s\n",
      "24/11/24 23:51:16 INFO CodeGenerator: Code generated in 7.38 ms\n"
     ]
    }
   ],
   "source": [
    "df.show(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48db5f8e-367e-4a07-800a-f79ddd40fc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          film_words|\n",
      "+--------------------+\n",
      "|[Zack, and, Miri,...|\n",
      "| [Youth, in, Revolt]|\n",
      "|[You, Will, Meet,...|\n",
      "|    [When, in, Rome]|\n",
      "|[What, Happens, i...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 23:51:22 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/11/24 23:51:22 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/11/24 23:51:22 INFO CodeGenerator: Code generated in 8.231083 ms\n",
      "24/11/24 23:51:22 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 353.1 KiB, free 364.0 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.1.68:55373 in memory (size: 35.1 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:22 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 35.1 KiB, free 364.3 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.1.68:55373 in memory (size: 8.8 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.1.68:55373 (size: 35.1 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:22 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.1.68:55373 in memory (size: 8.2 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4199377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.1.68:55373 in memory (size: 35.1 KiB, free: 366.1 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.1.68:55373 in memory (size: 8.2 KiB, free: 366.2 MiB)\n",
      "24/11/24 23:51:22 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.1.68:55373 in memory (size: 35.1 KiB, free: 366.2 MiB)\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Final stage: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.1.68:55373 in memory (size: 35.1 KiB, free: 366.2 MiB)\n",
      "24/11/24 23:51:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 16.3 KiB, free 365.5 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.1.68:55373 in memory (size: 8.2 KiB, free: 366.2 MiB)\n",
      "24/11/24 23:51:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 365.5 MiB)\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.1.68:55373 (size: 8.0 KiB, free: 366.2 MiB)\n",
      "24/11/24 23:51:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585\n",
      "24/11/24 23:51:22 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.1.68:55373 in memory (size: 35.1 KiB, free: 366.3 MiB)\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/11/24 23:51:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "24/11/24 23:51:22 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (192.168.1.68, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes) \n",
      "24/11/24 23:51:22 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)\n",
      "24/11/24 23:51:22 INFO CodeGenerator: Code generated in 5.217292 ms\n",
      "24/11/24 23:51:22 INFO FileScanRDD: Reading File path: file:///Users/tuzhbagrigoriy/Downloads/movies.csv, range: 0-5073, partition values: [empty row]\n",
      "24/11/24 23:51:22 INFO CodeGenerator: Code generated in 4.077708 ms\n",
      "24/11/24 23:51:22 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1728 bytes result sent to driver\n",
      "24/11/24 23:51:22 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 16 ms on 192.168.1.68 (executor driver) (1/1)\n",
      "24/11/24 23:51:22 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "24/11/24 23:51:22 INFO DAGScheduler: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0) finished in 0,019 s\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/11/24 23:51:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "24/11/24 23:51:22 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0,021428 s\n",
      "24/11/24 23:51:22 INFO CodeGenerator: Code generated in 3.572208 ms\n"
     ]
    }
   ],
   "source": [
    "df.select('film_words').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d524f-29f0-46f9-82ad-30e5db58dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('counted', col('film_words'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
